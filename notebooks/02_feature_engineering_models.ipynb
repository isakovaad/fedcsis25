{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79a8a775-cb54-4098-bba6-56b36a4cd4f7",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "682b434e-2f55-4853-a3e8-3d614cd36f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chess\n",
    "import re\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6263f005-ad7b-4b2d-a7dd-5302615304e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_cleaned.csv')\n",
    "test_df = pd.read_csv('test_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f8b791-380d-4167-b4ad-2f086c6c65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessPuzzleFeatureEngineer:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.piece_values = {'p': 1, 'n': 3, 'b': 3, 'r': 5, 'q': 9, 'k': 0}\n",
    "        \n",
    "    def create_advanced_features(self, df, sample_size=None):\n",
    "        \n",
    "        print(\"Starting Advanced Feature Engineering...\")\n",
    "        \n",
    "        if sample_size:\n",
    "            print(f\"Working with sample of {sample_size} records\")\n",
    "            df = df.sample(n=min(sample_size, len(df)), random_state=42).reset_index(drop=True)\n",
    "        \n",
    "        features = self._create_basic_features(df)\n",
    "        \n",
    "        print(\"Creating enhanced success probability features...\")\n",
    "        success_features = self._create_success_probability_features(df)\n",
    "        features = pd.concat([features, success_features], axis=1)\n",
    "        \n",
    "        print(\"Extracting chess position features...\")\n",
    "        position_features = self._create_position_features(df)\n",
    "        features = pd.concat([features, position_features], axis=1)\n",
    "        \n",
    "        print(\"Analyzing move sequences...\")\n",
    "        move_features = self._create_move_sequence_features(df)\n",
    "        features = pd.concat([features, move_features], axis=1)\n",
    "        \n",
    "        print(\"Processing themes and metadata...\")\n",
    "        theme_features = self._create_theme_features(df)\n",
    "        features = pd.concat([features, theme_features], axis=1)\n",
    "        \n",
    "        print(\"Creating feature interactions...\")\n",
    "        interaction_features = self._create_interaction_features(features)\n",
    "        features = pd.concat([features, interaction_features], axis=1)\n",
    "        \n",
    "        print(f\"Feature engineering complete! Created {len(features.columns)} features\")\n",
    "        return features.fillna(0)\n",
    "    \n",
    "    def _create_basic_features(self, df):\n",
    "        features = pd.DataFrame()\n",
    "        features['PuzzleId'] = df['PuzzleId']\n",
    "        \n",
    "        success_cols = [col for col in df.columns if 'success_prob' in col]\n",
    "        for col in success_cols:\n",
    "            features[col] = df[col].fillna(0)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _create_success_probability_features(self, df):\n",
    "        \n",
    "        features = pd.DataFrame()\n",
    "        \n",
    "        success_cols = [col for col in df.columns if 'success_prob' in col]\n",
    "        rapid_cols = [col for col in success_cols if 'rapid' in col]\n",
    "        blitz_cols = [col for col in success_cols if 'blitz' in col]\n",
    "        \n",
    "        if not rapid_cols or not blitz_cols:\n",
    "            return features\n",
    "        \n",
    "        features['rapid_mean'] = df[rapid_cols].mean(axis=1)\n",
    "        features['rapid_std'] = df[rapid_cols].std(axis=1).fillna(0)\n",
    "        features['rapid_min'] = df[rapid_cols].min(axis=1)\n",
    "        features['rapid_max'] = df[rapid_cols].max(axis=1)\n",
    "        features['rapid_range'] = features['rapid_max'] - features['rapid_min']\n",
    "        \n",
    "        features['blitz_mean'] = df[blitz_cols].mean(axis=1)\n",
    "        features['blitz_std'] = df[blitz_cols].std(axis=1).fillna(0)\n",
    "        features['blitz_min'] = df[blitz_cols].min(axis=1)\n",
    "        features['blitz_max'] = df[blitz_cols].max(axis=1)\n",
    "        features['blitz_range'] = features['blitz_max'] - features['blitz_min']\n",
    "        \n",
    "        features['rapid_blitz_diff'] = features['rapid_mean'] - features['blitz_mean']\n",
    "        features['rapid_blitz_ratio'] = features['rapid_mean'] / (features['blitz_mean'] + 0.001)\n",
    "        \n",
    "        if 'success_prob_rapid_1050' in df.columns and 'success_prob_rapid_1150' in df.columns:\n",
    "            features['skill_gap_1050_1150'] = df['success_prob_rapid_1150'] - df['success_prob_rapid_1050']\n",
    "            features['skill_ratio_1050_1150'] = df['success_prob_rapid_1150'] / (df['success_prob_rapid_1050'] + 0.001)\n",
    "        \n",
    "        features['difficulty_slope'] = self._calculate_difficulty_slope(df, rapid_cols)\n",
    "        features['difficulty_inflection'] = self._find_difficulty_inflection(df, rapid_cols)\n",
    "        \n",
    "        if 'success_prob_rapid_1050' in df.columns and 'success_prob_blitz_1050' in df.columns:\n",
    "            features['time_pressure_1050'] = df['success_prob_rapid_1050'] - df['success_prob_blitz_1050']\n",
    "        \n",
    "        if 'success_prob_rapid_1150' in df.columns and 'success_prob_blitz_1150' in df.columns:\n",
    "            features['time_pressure_1150'] = df['success_prob_rapid_1150'] - df['success_prob_blitz_1150']\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _calculate_difficulty_slope(self, df, rating_cols):\n",
    "        slopes = []\n",
    "        ratings = [int(col.split('_')[-1]) for col in rating_cols]\n",
    "        \n",
    "        for idx in range(len(df)):\n",
    "            success_rates = [df[col].iloc[idx] for col in rating_cols]\n",
    "            slope = np.polyfit(ratings, success_rates, 1)[0] if len(ratings) > 1 else 0\n",
    "            slopes.append(slope)\n",
    "        \n",
    "        return slopes\n",
    "    \n",
    "    def _find_difficulty_inflection(self, df, rating_cols):\n",
    "        inflections = []\n",
    "        \n",
    "        for idx in range(len(df)):\n",
    "            success_rates = [df[col].iloc[idx] for col in rating_cols]\n",
    "            if len(success_rates) < 3:\n",
    "                inflections.append(0)\n",
    "                continue\n",
    "            \n",
    "            diffs = [success_rates[i+1] - success_rates[i] for i in range(len(success_rates)-1)]\n",
    "            max_diff_idx = np.argmax(diffs) if diffs else 0\n",
    "            inflections.append(max_diff_idx)\n",
    "        \n",
    "        return inflections\n",
    "    \n",
    "    def _create_position_features(self, df):\n",
    "        features = pd.DataFrame()\n",
    "        \n",
    "        print(\"  Parsing FEN strings...\")\n",
    "        position_data = []\n",
    "        \n",
    "        for idx, fen in enumerate(df['FEN']):\n",
    "            if idx % 10000 == 0:\n",
    "                print(f\"    Processed {idx}/{len(df)} positions\")\n",
    "            \n",
    "            pos_features = self._parse_fen_features(fen)\n",
    "            position_data.append(pos_features)\n",
    "        \n",
    "        position_df = pd.DataFrame(position_data).fillna(0)\n",
    "        return position_df\n",
    "    \n",
    "    def _parse_fen_features(self, fen_string):\n",
    "        if pd.isna(fen_string) or not fen_string:\n",
    "            return self._get_empty_position_features()\n",
    "        \n",
    "        try:\n",
    "            board = chess.Board(fen_string)\n",
    "            features = {}\n",
    "            \n",
    "            white_material, black_material = self._calculate_material(board)\n",
    "            features['white_material'] = white_material\n",
    "            features['black_material'] = black_material\n",
    "            features['material_balance'] = white_material - black_material\n",
    "            features['total_material'] = white_material + black_material\n",
    "            features['material_ratio'] = white_material / max(black_material, 1)\n",
    "            \n",
    "            for piece_symbol in ['P', 'N', 'B', 'R', 'Q', 'K', 'p', 'n', 'b', 'r', 'q', 'k']:\n",
    "                count = len([sq for sq in chess.SQUARES \n",
    "                           if board.piece_at(sq) and board.piece_at(sq).symbol() == piece_symbol])\n",
    "                features[f'{piece_symbol}_count'] = count\n",
    "            \n",
    "            if features['total_material'] > 50:\n",
    "                features['game_phase'] = 0\n",
    "            elif features['total_material'] > 15:\n",
    "                features['game_phase'] = 1\n",
    "            else:\n",
    "                features['game_phase'] = 2\n",
    "            \n",
    "            white_king = board.king(chess.WHITE)\n",
    "            black_king = board.king(chess.BLACK)\n",
    "            \n",
    "            if white_king and black_king:\n",
    "                features['king_distance'] = chess.square_distance(white_king, black_king)\n",
    "                features['white_king_center'] = self._is_center_square(white_king)\n",
    "                features['black_king_center'] = self._is_center_square(black_king)\n",
    "            else:\n",
    "                features['king_distance'] = 0\n",
    "                features['white_king_center'] = 0\n",
    "                features['black_king_center'] = 0\n",
    "            \n",
    "            features['white_to_move'] = int(board.turn == chess.WHITE)\n",
    "            features['in_check'] = int(board.is_check())\n",
    "            features['num_legal_moves'] = len(list(board.legal_moves))\n",
    "            \n",
    "            features['can_castle'] = int(any([\n",
    "                board.has_kingside_castling_rights(chess.WHITE),\n",
    "                board.has_queenside_castling_rights(chess.WHITE),\n",
    "                board.has_kingside_castling_rights(chess.BLACK),\n",
    "                board.has_queenside_castling_rights(chess.BLACK)\n",
    "            ]))\n",
    "            \n",
    "            return features\n",
    "            \n",
    "        except Exception as e:\n",
    "            return self._get_empty_position_features()\n",
    "    \n",
    "    def _calculate_material(self, board):\n",
    "        white_material = black_material = 0\n",
    "        \n",
    "        for square in chess.SQUARES:\n",
    "            piece = board.piece_at(square)\n",
    "            if piece:\n",
    "                value = self.piece_values.get(piece.symbol().lower(), 0)\n",
    "                if piece.color == chess.WHITE:\n",
    "                    white_material += value\n",
    "                else:\n",
    "                    black_material += value\n",
    "        \n",
    "        return white_material, black_material\n",
    "    \n",
    "    def _is_center_square(self, square):\n",
    "        if square is None:\n",
    "            return 0\n",
    "        file = chess.square_file(square)\n",
    "        rank = chess.square_rank(square)\n",
    "        return int(file in [3, 4] and rank in [3, 4])\n",
    "    \n",
    "    def _get_empty_position_features(self):\n",
    "        features = {}\n",
    "        \n",
    "        for key in ['white_material', 'black_material', 'material_balance', 'total_material', 'material_ratio']:\n",
    "            features[key] = 0\n",
    "        \n",
    "        for piece in ['P', 'N', 'B', 'R', 'Q', 'K', 'p', 'n', 'b', 'r', 'q', 'k']:\n",
    "            features[f'{piece}_count'] = 0\n",
    "        \n",
    "        for key in ['game_phase', 'king_distance', 'white_king_center', 'black_king_center',\n",
    "                   'white_to_move', 'in_check', 'num_legal_moves', 'can_castle']:\n",
    "            features[key] = 0\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _create_move_sequence_features(self, df):\n",
    "        features = pd.DataFrame()\n",
    "        \n",
    "        print(\"  Analyzing move sequences...\")\n",
    "        move_data = []\n",
    "        \n",
    "        for idx, moves_str in enumerate(df['Moves']):\n",
    "            if idx % 10000 == 0:\n",
    "                print(f\"    Processed {idx}/{len(df)} move sequences\")\n",
    "            \n",
    "            move_features = self._parse_move_features(moves_str)\n",
    "            move_data.append(move_features)\n",
    "        \n",
    "        move_df = pd.DataFrame(move_data).fillna(0)\n",
    "        return move_df\n",
    "    \n",
    "    def _parse_move_features(self, moves_string):\n",
    "        if pd.isna(moves_string) or not moves_string:\n",
    "            return {'move_count': 0, 'captures_count': 0, 'checks_count': 0}\n",
    "        \n",
    "        moves = moves_string.strip().split()\n",
    "        features = {}\n",
    "        \n",
    "        features['move_count'] = len(moves)\n",
    "        features['captures_count'] = sum(1 for move in moves if 'x' in move)\n",
    "        features['checks_count'] = sum(1 for move in moves if '+' in move)\n",
    "        features['castling_count'] = sum(1 for move in moves if move in ['O-O', 'O-O-O'])\n",
    "        features['promotion_count'] = sum(1 for move in moves if '=' in move)\n",
    "        \n",
    "        features['avg_move_length'] = np.mean([len(move) for move in moves]) if moves else 0\n",
    "        features['complex_moves'] = sum(1 for move in moves if len(move) > 4)\n",
    "        \n",
    "        features['capture_rate'] = features['captures_count'] / max(features['move_count'], 1)\n",
    "        features['check_rate'] = features['checks_count'] / max(features['move_count'], 1)\n",
    "        \n",
    "        piece_moves = {'K': 0, 'Q': 0, 'R': 0, 'B': 0, 'N': 0}\n",
    "        for move in moves:\n",
    "            if move and move[0] in piece_moves:\n",
    "                piece_moves[move[0]] += 1\n",
    "        \n",
    "        for piece, count in piece_moves.items():\n",
    "            features[f'{piece}_moves'] = count\n",
    "        \n",
    "        features['pawn_moves'] = sum(1 for move in moves \n",
    "                                   if move and move[0] not in ['K', 'Q', 'R', 'B', 'N', 'O'])\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _create_theme_features(self, df):\n",
    "        features = pd.DataFrame()\n",
    "        \n",
    "        for col in ['NbPlays', 'Popularity', 'RatingDeviation']:\n",
    "            if col in df.columns:\n",
    "                features[col] = df[col].fillna(0)\n",
    "                features[f'log_{col.lower()}'] = np.log1p(df[col].fillna(0))\n",
    "        \n",
    "        if 'Themes' in df.columns:\n",
    "            theme_features = self._parse_themes(df['Themes'])\n",
    "            features = pd.concat([features, theme_features], axis=1)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def _parse_themes(self, theme_series):\n",
    "        important_themes = [\n",
    "            'mate', 'mateIn1', 'mateIn2', 'mateIn3', 'mateIn4', 'mateIn5',\n",
    "            'endgame', 'middlegame', 'opening',\n",
    "            'advantage', 'crushing', 'equality',\n",
    "            'short', 'long', 'veryLong',\n",
    "            'fork', 'pin', 'skewer', 'discoveredAttack', 'deflection',\n",
    "            'sacrifice', 'attraction', 'clearance',\n",
    "            'backRankMate', 'smotheredMate', 'anastasiasMate',\n",
    "            'rookEndgame', 'queenEndgame', 'pawnEndgame', 'knightEndgame', 'bishopEndgame',\n",
    "            'kingsideAttack', 'queensideAttack',\n",
    "            'trappedPiece', 'hangingPiece',\n",
    "            'master', 'superGM'\n",
    "        ]\n",
    "        \n",
    "        theme_features = pd.DataFrame()\n",
    "        \n",
    "        for theme in important_themes:\n",
    "            theme_features[f'theme_{theme}'] = theme_series.fillna('').str.contains(theme, case=False).astype(int)\n",
    "        \n",
    "        theme_features['total_themes'] = theme_series.fillna('').str.split().str.len()\n",
    "        theme_features['has_mate_theme'] = theme_series.fillna('').str.contains('mate', case=False).astype(int)\n",
    "        theme_features['has_tactic_theme'] = theme_series.fillna('').str.contains('fork|pin|skewer|deflection', case=False).astype(int)\n",
    "        \n",
    "        return theme_features\n",
    "    \n",
    "    def _create_interaction_features(self, features):\n",
    "        interactions = pd.DataFrame()\n",
    "        \n",
    "        if 'rapid_mean' in features.columns and 'move_count' in features.columns:\n",
    "            interactions['rapid_mean_x_move_count'] = features['rapid_mean'] * features['move_count']\n",
    "        \n",
    "        if 'blitz_mean' in features.columns and 'captures_count' in features.columns:\n",
    "            interactions['blitz_mean_x_captures'] = features['blitz_mean'] * features['captures_count']\n",
    "        \n",
    "        if 'material_balance' in features.columns and 'rapid_mean' in features.columns:\n",
    "            interactions['material_x_rapid'] = features['material_balance'] * features['rapid_mean']\n",
    "        \n",
    "        success_cols = [col for col in features.columns if 'success_prob' in col]\n",
    "        if len(success_cols) >= 2:\n",
    "            if 'success_prob_rapid_1150' in features.columns and 'success_prob_rapid_1050' in features.columns:\n",
    "                interactions['success_1150_x_1050'] = (features['success_prob_rapid_1150'] * \n",
    "                                                     features['success_prob_rapid_1050'])\n",
    "        \n",
    "        return interactions\n",
    "\n",
    "def run_feature_engineering(train_df, test_df, sample_size=100000):\n",
    "    \n",
    "    print(\"CHESS PUZZLE FEATURE ENGINEERING PIPELINE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    feature_engineer = ChessPuzzleFeatureEngineer()\n",
    "    \n",
    "    print(\"\\nProcessing training data...\")\n",
    "    train_features = feature_engineer.create_advanced_features(train_df, sample_size=sample_size)\n",
    "    \n",
    "    print(\"\\nProcessing test data...\")\n",
    "    test_features = feature_engineer.create_advanced_features(test_df)\n",
    "    \n",
    "    common_features = list(set(train_features.columns) & set(test_features.columns))\n",
    "    train_features = train_features[common_features]\n",
    "    test_features = test_features[common_features]\n",
    "    \n",
    "    print(f\"\\nFeature engineering complete!\")\n",
    "    print(f\"Training features shape: {train_features.shape}\")\n",
    "    print(f\"Test features shape: {test_features.shape}\")\n",
    "    print(f\"Total features created: {len(common_features)}\")\n",
    "    \n",
    "    feature_types = {\n",
    "        'success_prob': len([col for col in common_features if 'success_prob' in col]),\n",
    "        'position': len([col for col in common_features if any(x in col for x in ['material', 'piece', 'king', 'check'])]),\n",
    "        'moves': len([col for col in common_features if any(x in col for x in ['move', 'capture', 'check'])]),\n",
    "        'themes': len([col for col in common_features if 'theme' in col]),\n",
    "        'interactions': len([col for col in common_features if '_x_' in col]),\n",
    "        'other': len([col for col in common_features if not any(x in col for x in ['success_prob', 'material', 'piece', 'king', 'move', 'capture', 'theme', '_x_'])])\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nFeature breakdown:\")\n",
    "    for feat_type, count in feature_types.items():\n",
    "        print(f\"  {feat_type}: {count} features\")\n",
    "    \n",
    "    return train_features, test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77815b6e-3b9d-4115-a071-315bc909d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     print(\"Ready to run advanced feature engineering!\")\n",
    "#     print(\"Use: train_features, test_features = run_feature_engineering(train_df, test_df)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d85a87-f841-4d8a-9c89-249dd7d1465d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHESS PUZZLE FEATURE ENGINEERING PIPELINE\n",
      "============================================================\n",
      "\n",
      "Processing training data...\n",
      "Starting Advanced Feature Engineering...\n",
      "Working with sample of 100000 records\n",
      "Creating enhanced success probability features...\n",
      "Extracting chess position features...\n",
      "  Parsing FEN strings...\n",
      "    Processed 0/100000 positions\n",
      "    Processed 10000/100000 positions\n",
      "    Processed 20000/100000 positions\n",
      "    Processed 30000/100000 positions\n",
      "    Processed 40000/100000 positions\n",
      "    Processed 50000/100000 positions\n",
      "    Processed 60000/100000 positions\n",
      "    Processed 70000/100000 positions\n",
      "    Processed 80000/100000 positions\n",
      "    Processed 90000/100000 positions\n",
      "Analyzing move sequences...\n",
      "  Analyzing move sequences...\n",
      "    Processed 0/100000 move sequences\n",
      "    Processed 10000/100000 move sequences\n",
      "    Processed 20000/100000 move sequences\n",
      "    Processed 30000/100000 move sequences\n",
      "    Processed 40000/100000 move sequences\n",
      "    Processed 50000/100000 move sequences\n",
      "    Processed 60000/100000 move sequences\n",
      "    Processed 70000/100000 move sequences\n",
      "    Processed 80000/100000 move sequences\n",
      "    Processed 90000/100000 move sequences\n",
      "Processing themes and metadata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Cellar/jupyterlab/4.3.1_1/libexec/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: divide by zero encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n",
      "/opt/homebrew/Cellar/jupyterlab/4.3.1_1/libexec/lib/python3.12/site-packages/pandas/core/arraylike.py:399: RuntimeWarning: invalid value encountered in log1p\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating feature interactions...\n",
      "Feature engineering complete! Created 131 features\n",
      "\n",
      "Processing test data...\n",
      "Starting Advanced Feature Engineering...\n",
      "Creating enhanced success probability features...\n",
      "Extracting chess position features...\n",
      "  Parsing FEN strings...\n",
      "    Processed 0/2235 positions\n",
      "Analyzing move sequences...\n",
      "  Analyzing move sequences...\n",
      "    Processed 0/2235 move sequences\n",
      "Processing themes and metadata...\n",
      "Creating feature interactions...\n",
      "Feature engineering complete! Created 85 features\n",
      "\n",
      "Feature engineering complete!\n",
      "Training features shape: (100000, 85)\n",
      "Test features shape: (2235, 85)\n",
      "Total features created: 85\n",
      "\n",
      "Feature breakdown:\n",
      "  success_prob: 22 features\n",
      "  position: 12 features\n",
      "  moves: 18 features\n",
      "  themes: 0 features\n",
      "  interactions: 4 features\n",
      "  other: 38 features\n"
     ]
    }
   ],
   "source": [
    "train_features, test_features = run_feature_engineering(\n",
    "    train_df, \n",
    "    test_df, \n",
    "    sample_size=100000  # Start with 100k for speed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccdfe92-1399-48cb-b326-e0a71fc113f1",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3292caa5-1b73-49b6-9dae-8b535dde08ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7097698-e68b-4a24-b231-dd5b95bc3e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChessFeatureEmbedding(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.theme_embedding = nn.Embedding(\n",
    "            config['theme_vocab_size'], \n",
    "            config['theme_embed_dim']\n",
    "        )\n",
    "        \n",
    "        self.numerical_projection = nn.Linear(\n",
    "            config['num_numerical_features'], \n",
    "            config['numerical_embed_dim']\n",
    "        )\n",
    "        \n",
    "        self.success_prob_projection = nn.Linear(\n",
    "            config['num_success_prob_features'],\n",
    "            config['success_prob_embed_dim']\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(config['dropout'])\n",
    "        \n",
    "    def forward(self, features_dict):\n",
    "        embeddings = []\n",
    "        \n",
    "        if 'theme_features' in features_dict:\n",
    "            theme_emb = self.theme_embedding(features_dict['theme_features'])\n",
    "            theme_emb = theme_emb.mean(dim=1)\n",
    "            embeddings.append(theme_emb)\n",
    "        \n",
    "        if 'numerical_features' in features_dict:\n",
    "            num_emb = self.numerical_projection(features_dict['numerical_features'])\n",
    "            embeddings.append(num_emb)\n",
    "        \n",
    "        if 'success_prob_features' in features_dict:\n",
    "            success_emb = self.success_prob_projection(features_dict['success_prob_features'])\n",
    "            embeddings.append(success_emb)\n",
    "        \n",
    "        combined = torch.cat(embeddings, dim=-1)\n",
    "        return self.dropout(combined)\n",
    "\n",
    "class ChessTransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attention = nn.MultiheadAttention(\n",
    "            embed_dim, num_heads, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_dim, ff_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(ff_dim, embed_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.attention(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        \n",
    "        ff_out = self.feed_forward(x)\n",
    "        x = self.norm2(x + ff_out)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ChessPuzzleTransformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.feature_embedding = ChessFeatureEmbedding(config)\n",
    "        \n",
    "        total_embed_dim = (\n",
    "            config.get('theme_embed_dim', 32) +\n",
    "            config.get('numerical_embed_dim', 64) +\n",
    "            config.get('success_prob_embed_dim', 128)\n",
    "        )\n",
    "        \n",
    "        self.pos_encoding = nn.Parameter(\n",
    "            torch.randn(1, config['max_seq_len'], total_embed_dim) * 0.1\n",
    "        )\n",
    "        \n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            ChessTransformerBlock(\n",
    "                total_embed_dim, \n",
    "                config['num_heads'], \n",
    "                config['ff_dim'],\n",
    "                config['dropout']\n",
    "            ) for _ in range(config['num_layers'])\n",
    "        ])\n",
    "        \n",
    "        self.output_head = nn.Sequential(\n",
    "            nn.LayerNorm(total_embed_dim),\n",
    "            nn.Linear(total_embed_dim, config['hidden_dim']),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(config['dropout']),\n",
    "            nn.Linear(config['hidden_dim'], config['hidden_dim'] // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(config['dropout']),\n",
    "            nn.Linear(config['hidden_dim'] // 2, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, features_dict):\n",
    "        x = self.feature_embedding(features_dict)\n",
    "        \n",
    "        if x.dim() == 2:\n",
    "            x = x.unsqueeze(1)\n",
    "        \n",
    "        seq_len = min(x.size(1), self.config['max_seq_len'])\n",
    "        x = x[:, :seq_len, :] + self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        for transformer_block in self.transformer_blocks:\n",
    "            x = transformer_block(x)\n",
    "        \n",
    "        x = x.mean(dim=1)\n",
    "        \n",
    "        output = self.output_head(x)\n",
    "        return output.squeeze(-1)\n",
    "\n",
    "class TreeNeuralHybrid(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.neural_net = nn.Sequential(\n",
    "            nn.Linear(config['neural_input_dim'], 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            \n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "        \n",
    "        self.combination_layer = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, neural_features, tree_predictions=None):\n",
    "        neural_output = self.neural_net(neural_features)\n",
    "        \n",
    "        if tree_predictions is not None:\n",
    "            combined = torch.cat([neural_output, tree_predictions.unsqueeze(-1)], dim=-1)\n",
    "            final_output = self.combination_layer(combined)\n",
    "            return final_output.squeeze(-1)\n",
    "        \n",
    "        return neural_output.squeeze(-1)\n",
    "\n",
    "class ChessHybridModel:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.tree_model = None\n",
    "        self.neural_model = None\n",
    "        self.scaler = StandardScaler()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    def prepare_features(self, features_df):\n",
    "        tree_features = [col for col in features_df.columns if any(x in col.lower() for x in [\n",
    "            'success_prob', 'material', 'move_count', 'theme_', 'nbplays', 'popularity',\n",
    "            'captures_count', 'checks_count', 'piece_count', 'game_phase'\n",
    "        ])]\n",
    "        \n",
    "        neural_features = [col for col in features_df.columns if any(x in col.lower() for x in [\n",
    "            '_x_', 'interaction', 'ratio', 'std', 'mean', 'range', 'slope', 'inflection'\n",
    "        ])]\n",
    "        \n",
    "        remaining_features = [col for col in features_df.columns \n",
    "                            if col not in tree_features + neural_features and col != 'PuzzleId']\n",
    "        neural_features.extend(remaining_features)\n",
    "        \n",
    "        tree_X = features_df[tree_features].fillna(0)\n",
    "        neural_X = features_df[neural_features].fillna(0)\n",
    "        \n",
    "        return tree_X, neural_X, tree_features, neural_features\n",
    "    \n",
    "    def train(self, X_train, y_train, X_val, y_val):\n",
    "        print(\"Training Tree Component (LightGBM)...\")\n",
    "        \n",
    "        tree_X_train, neural_X_train, tree_features, neural_features = self.prepare_features(X_train)\n",
    "        tree_X_val, neural_X_val, _, _ = self.prepare_features(X_val)\n",
    "        \n",
    "        print(f\"  Tree features: {len(tree_features)}\")\n",
    "        print(f\"  Neural features: {len(neural_features)}\")\n",
    "        \n",
    "        train_data = lgb.Dataset(tree_X_train, label=y_train)\n",
    "        val_data = lgb.Dataset(tree_X_val, label=y_val, reference=train_data)\n",
    "        \n",
    "        lgb_params = {\n",
    "            'objective': 'regression',\n",
    "            'metric': 'rmse',\n",
    "            'boosting_type': 'gbdt',\n",
    "            'num_leaves': 100,\n",
    "            'learning_rate': 0.05,\n",
    "            'feature_fraction': 0.8,\n",
    "            'bagging_fraction': 0.8,\n",
    "            'bagging_freq': 5,\n",
    "            'verbose': -1,\n",
    "            'random_state': 42\n",
    "        }\n",
    "        \n",
    "        self.tree_model = lgb.train(\n",
    "            lgb_params,\n",
    "            train_data,\n",
    "            valid_sets=[val_data],\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        tree_pred_train = self.tree_model.predict(tree_X_train)\n",
    "        tree_pred_val = self.tree_model.predict(tree_X_val)\n",
    "        \n",
    "        print(\"Training Neural Component...\")\n",
    "        \n",
    "        neural_X_train_scaled = self.scaler.fit_transform(neural_X_train)\n",
    "        neural_X_val_scaled = self.scaler.transform(neural_X_val)\n",
    "        \n",
    "        neural_config = {\n",
    "            'neural_input_dim': neural_X_train_scaled.shape[1]\n",
    "        }\n",
    "        self.neural_model = TreeNeuralHybrid(neural_config).to(self.device)\n",
    "        \n",
    "        optimizer = torch.optim.AdamW(self.neural_model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, factor=0.5)\n",
    "        criterion = nn.MSELoss()\n",
    "        \n",
    "        train_neural_tensor = torch.FloatTensor(neural_X_train_scaled).to(self.device)\n",
    "        train_tree_tensor = torch.FloatTensor(tree_pred_train).to(self.device)\n",
    "        train_target_tensor = torch.FloatTensor(y_train.values).to(self.device)\n",
    "        \n",
    "        val_neural_tensor = torch.FloatTensor(neural_X_val_scaled).to(self.device)\n",
    "        val_tree_tensor = torch.FloatTensor(tree_pred_val).to(self.device)\n",
    "        val_target_tensor = torch.FloatTensor(y_val.values).to(self.device)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        for epoch in range(200):\n",
    "            self.neural_model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predictions = self.neural_model(train_neural_tensor, train_tree_tensor)\n",
    "            loss = criterion(predictions, train_target_tensor)\n",
    "            \n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(self.neural_model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            self.neural_model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_predictions = self.neural_model(val_neural_tensor, val_tree_tensor)\n",
    "                val_loss = criterion(val_predictions, val_target_tensor)\n",
    "            \n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "                torch.save(self.neural_model.state_dict(), 'best_hybrid_model.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                if patience_counter >= 20:\n",
    "                    break\n",
    "            \n",
    "            if epoch % 25 == 0:\n",
    "                print(f\"  Epoch {epoch}: Train Loss = {loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "        \n",
    "        self.neural_model.load_state_dict(torch.load('best_hybrid_model.pth'))\n",
    "        \n",
    "        print(\"Hybrid model training complete!\")\n",
    "        \n",
    "        return best_val_loss.item()\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        tree_X_test, neural_X_test, _, _ = self.prepare_features(X_test)\n",
    "        \n",
    "        tree_predictions = self.tree_model.predict(tree_X_test)\n",
    "        \n",
    "        neural_X_test_scaled = self.scaler.transform(neural_X_test)\n",
    "        neural_tensor = torch.FloatTensor(neural_X_test_scaled).to(self.device)\n",
    "        tree_tensor = torch.FloatTensor(tree_predictions).to(self.device)\n",
    "        \n",
    "        self.neural_model.eval()\n",
    "        with torch.no_grad():\n",
    "            hybrid_predictions = self.neural_model(neural_tensor, tree_tensor)\n",
    "        \n",
    "        return hybrid_predictions.cpu().numpy()\n",
    "\n",
    "class ChessPuzzleDataset(Dataset):\n",
    "    def __init__(self, features_df, targets=None, config=None):\n",
    "        self.features_df = features_df\n",
    "        self.targets = targets\n",
    "        self.config = config\n",
    "        \n",
    "        self.success_prob_features = [col for col in features_df.columns if 'success_prob' in col]\n",
    "        self.theme_features = [col for col in features_df.columns if 'theme_' in col]\n",
    "        self.numerical_features = [col for col in features_df.columns \n",
    "                                 if col not in self.success_prob_features + self.theme_features\n",
    "                                 and col != 'PuzzleId']\n",
    "        \n",
    "        self.scaler = StandardScaler()\n",
    "        if self.numerical_features:\n",
    "            self.numerical_data = self.scaler.fit_transform(\n",
    "                features_df[self.numerical_features].fillna(0)\n",
    "            )\n",
    "        else:\n",
    "            self.numerical_data = np.array([])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        features_dict = {}\n",
    "        \n",
    "        if self.success_prob_features:\n",
    "            features_dict['success_prob_features'] = torch.FloatTensor(\n",
    "                self.features_df[self.success_prob_features].iloc[idx].fillna(0).values\n",
    "            )\n",
    "        \n",
    "        if self.theme_features:\n",
    "            theme_indices = torch.LongTensor([\n",
    "                i for i, val in enumerate(self.features_df[self.theme_features].iloc[idx].values) \n",
    "                if val > 0\n",
    "            ])\n",
    "            if len(theme_indices) == 0:\n",
    "                theme_indices = torch.LongTensor([0])\n",
    "            features_dict['theme_features'] = theme_indices\n",
    "        \n",
    "        if len(self.numerical_data) > 0:\n",
    "            features_dict['numerical_features'] = torch.FloatTensor(self.numerical_data[idx])\n",
    "        \n",
    "        if self.targets is not None:\n",
    "            return features_dict, torch.FloatTensor([self.targets.iloc[idx]])\n",
    "        \n",
    "        return features_dict\n",
    "\n",
    "def train_transformer_model(train_features, test_features, train_targets, sample_size=50000):\n",
    "    print(\"TRAINING TRANSFORMER MODEL\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    if len(train_features) > sample_size:\n",
    "        sample_idx = np.random.choice(len(train_features), sample_size, replace=False)\n",
    "        train_features_sample = train_features.iloc[sample_idx].reset_index(drop=True)\n",
    "        train_targets_sample = train_targets.iloc[sample_idx].reset_index(drop=True)\n",
    "    else:\n",
    "        train_features_sample = train_features\n",
    "        train_targets_sample = train_targets\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train_features_sample, train_targets_sample, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    theme_cols = [col for col in train_features.columns if 'theme_' in col]\n",
    "    success_prob_cols = [col for col in train_features.columns if 'success_prob' in col]\n",
    "    numerical_cols = [col for col in train_features.columns \n",
    "                     if col not in success_prob_cols + theme_cols and col != 'PuzzleId']\n",
    "    \n",
    "    config = {\n",
    "        'theme_vocab_size': len(theme_cols) + 1,\n",
    "        'theme_embed_dim': 32,\n",
    "        'numerical_embed_dim': 64,\n",
    "        'success_prob_embed_dim': 128,\n",
    "        'num_numerical_features': len(numerical_cols),\n",
    "        'num_success_prob_features': len(success_prob_cols),\n",
    "        'max_seq_len': 10,\n",
    "        'num_heads': 8,\n",
    "        'num_layers': 4,\n",
    "        'ff_dim': 512,\n",
    "        'hidden_dim': 256,\n",
    "        'dropout': 0.1\n",
    "    }\n",
    "    \n",
    "    print(f\"  Theme features: {len(theme_cols)}\")\n",
    "    print(f\"  Success prob features: {len(success_prob_cols)}\")\n",
    "    print(f\"  Numerical features: {len(numerical_cols)}\")\n",
    "    \n",
    "    train_dataset = ChessPuzzleDataset(X_train, y_train, config)\n",
    "    val_dataset = ChessPuzzleDataset(X_val, y_val, config)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = ChessPuzzleTransformer(config).to(device)\n",
    "    \n",
    "    print(f\"  Using device: {device}\")\n",
    "    print(f\"  Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience = 0\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_features, batch_targets in train_loader:\n",
    "            for key in batch_features:\n",
    "                batch_features[key] = batch_features[key].to(device)\n",
    "            batch_targets = batch_targets.to(device).squeeze()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(batch_features)\n",
    "            loss = criterion(predictions, batch_targets)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_features, batch_targets in val_loader:\n",
    "                for key in batch_features:\n",
    "                    batch_features[key] = batch_features[key].to(device)\n",
    "                batch_targets = batch_targets.to(device).squeeze()\n",
    "                \n",
    "                predictions = model(batch_features)\n",
    "                loss = criterion(predictions, batch_targets)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience = 0\n",
    "            torch.save(model.state_dict(), 'best_transformer_model.pth')\n",
    "        else:\n",
    "            patience += 1\n",
    "            if patience >= 15:\n",
    "                break\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"  Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n",
    "    \n",
    "    model.load_state_dict(torch.load('best_transformer_model.pth'))\n",
    "    \n",
    "    print(\"Transformer training complete!\")\n",
    "    \n",
    "    return model, config, best_val_loss\n",
    "\n",
    "def run_advanced_models_pipeline(train_features, test_features, train_df, sample_size=50000):\n",
    "    print(\"ADVANCED CHESS PUZZLE MODELS PIPELINE\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    y = train_df['Rating'].iloc[:len(train_features)]\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        train_features, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\nTRANSFORMER MODEL\")\n",
    "    print(\"-\" * 30)\n",
    "    try:\n",
    "        transformer_model, transformer_config, transformer_val_loss = train_transformer_model(\n",
    "            train_features, test_features, y, sample_size=sample_size\n",
    "        )\n",
    "        results['transformer'] = {\n",
    "            'model': transformer_model,\n",
    "            'config': transformer_config,\n",
    "            'val_loss': transformer_val_loss,\n",
    "            'rmse': np.sqrt(transformer_val_loss)\n",
    "        }\n",
    "        print(f\"Transformer RMSE: {results['transformer']['rmse']:.1f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Transformer training failed: {e}\")\n",
    "        results['transformer'] = {'rmse': float('inf')}\n",
    "    \n",
    "    print(\"\\nHYBRID TREE+NEURAL MODEL\")\n",
    "    print(\"-\" * 30)\n",
    "    try:\n",
    "        hybrid_config = {'neural_input_dim': X_train.shape[1] - 1}\n",
    "        hybrid_model = ChessHybridModel(hybrid_config)\n",
    "        \n",
    "        X_train_clean = X_train.drop(['PuzzleId'], axis=1, errors='ignore')\n",
    "        X_val_clean = X_val.drop(['PuzzleId'], axis=1, errors='ignore')\n",
    "        \n",
    "        hybrid_val_loss = hybrid_model.train(X_train_clean, y_train, X_val_clean, y_val)\n",
    "        results['hybrid'] = {\n",
    "            'model': hybrid_model,\n",
    "            'val_loss': hybrid_val_loss,\n",
    "            'rmse': np.sqrt(hybrid_val_loss)\n",
    "        }\n",
    "        print(f\"Hybrid RMSE: {results['hybrid']['rmse']:.1f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Hybrid training failed: {e}\")\n",
    "        results['hybrid'] = {'rmse': float('inf')}\n",
    "    \n",
    "    print(\"\\nMODEL COMPARISON\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Baseline (XGBoost):     RMSE = 337\")\n",
    "    \n",
    "    for model_name, result in results.items():\n",
    "        if 'rmse' in result and result['rmse'] != float('inf'):\n",
    "            improvement = ((337 - result['rmse']) / 337 * 100)\n",
    "            print(f\"{model_name.capitalize():20s} RMSE = {result['rmse']:.1f} ({improvement:+.1f}%)\")\n",
    "    \n",
    "    valid_models = {k: v for k, v in results.items() if v['rmse'] != float('inf')}\n",
    "    if valid_models:\n",
    "        best_model_name = min(valid_models.keys(), key=lambda k: valid_models[k]['rmse'])\n",
    "        print(f\"\\nBest Model: {best_model_name.upper()}\")\n",
    "    else:\n",
    "        print(\"\\nNo models trained successfully\")\n",
    "        best_model_name = None\n",
    "    \n",
    "    return results, best_model_name\n",
    "\n",
    "def generate_predictions(results, best_model_name, test_features):\n",
    "    if best_model_name is None or best_model_name not in results:\n",
    "        print(\"No valid model for predictions\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nGenerating predictions with {best_model_name.upper()} model...\")\n",
    "    \n",
    "    best_model = results[best_model_name]['model']\n",
    "    test_clean = test_features.drop(['PuzzleId'], axis=1, errors='ignore')\n",
    "    \n",
    "    if best_model_name == 'transformer':\n",
    "        print(\"Transformer predictions require special dataset handling\")\n",
    "        return None\n",
    "    \n",
    "    elif best_model_name == 'hybrid':\n",
    "        predictions = best_model.predict(test_clean)\n",
    "        predictions = np.round(predictions).astype(int)\n",
    "        \n",
    "        with open(f'{best_model_name}_submission.txt', 'w') as f:\n",
    "            for pred in predictions:\n",
    "                f.write(f\"{pred}\\n\")\n",
    "        \n",
    "        print(f\"Predictions saved to {best_model_name}_submission.txt\")\n",
    "        return predictions\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b6827c2-5bbf-4576-a161-a995306329bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADVANCED CHESS PUZZLE MODELS PIPELINE\n",
      "============================================================\n",
      "\n",
      "TRANSFORMER MODEL\n",
      "------------------------------\n",
      "TRAINING TRANSFORMER MODEL\n",
      "========================================\n",
      "  Theme features: 0\n",
      "  Success prob features: 22\n",
      "  Numerical features: 62\n",
      "  Using device: cpu\n",
      "  Model parameters: 1,830,753\n",
      "Transformer training failed: The size of tensor a (192) must match the size of tensor b (224) at non-singleton dimension 2\n",
      "\n",
      "HYBRID TREE+NEURAL MODEL\n",
      "------------------------------\n",
      "Training Tree Component (LightGBM)...\n",
      "  Tree features: 33\n",
      "  Neural features: 54\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1]\tvalid_0's rmse: 540.399\n",
      "Training Neural Component...\n",
      "  Epoch 0: Train Loss = 506212.6562, Val Loss = 489290.7500\n",
      "  Epoch 25: Train Loss = 472873.1250, Val Loss = 456861.1875\n",
      "  Epoch 50: Train Loss = 441103.4688, Val Loss = 425915.5938\n",
      "  Epoch 75: Train Loss = 410010.8438, Val Loss = 395175.9062\n",
      "  Epoch 100: Train Loss = 378626.0312, Val Loss = 363403.3125\n",
      "  Epoch 125: Train Loss = 346620.0000, Val Loss = 335390.2812\n",
      "  Epoch 150: Train Loss = 316269.2188, Val Loss = 314027.9375\n",
      "  Epoch 175: Train Loss = 294020.7500, Val Loss = 299972.8438\n",
      "Hybrid model training complete!\n",
      "Hybrid RMSE: 544.4\n",
      "\n",
      "MODEL COMPARISON\n",
      "========================================\n",
      "Baseline (XGBoost):     RMSE = 337\n",
      "Hybrid               RMSE = 544.4 (-61.5%)\n",
      "\n",
      "Best Model: HYBRID\n"
     ]
    }
   ],
   "source": [
    "results, best_model = run_advanced_models_pipeline(train_features, test_features, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a6eeb-67ad-4a1d-ba48-f99e505c23d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3dcd77-02d0-4a0b-9c67-43d551d90b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
